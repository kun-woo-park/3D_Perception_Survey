# RangeRCNN(2020)

[GitHub - SH-Tan/RangeRcnn-backbone: The backbone of the RangeRCNN, including DRB, Downsample, UpSample blocks.](https://github.com/SH-Tan/RangeRcnn-backbone)

## Characteristic(Contributions)

- Raw point data를 그대로 range image로 변환하여 사용하여 BEV보다  point loss를 줄임
- 확장된 CNN 구조를 제안하여 range image에 유연한 필터 구조를 적용함(Scale variation이 존재하는 range image에 적용하기에 적합함)
- RV-PV-BEV 모듈을 제안하여 range view의 feature들을 BEV feature들과 연관시켜 anchor generation의 정확도를 높임(range image는 입력 feature들을 추출하는 데는 유리하나, anchor generation에는 불리한 특성을 가짐)
- 3D convolution이나 point based convolution을 포함하지 않아 단순하고, 효율적임
- 2stage end to end 구조로, BEV에서 하지 못하는 height 예측을 포함함(Auto encoded range image값을 3D RoI Pooling block에 forward함으로써 height값을 예측함)

## Model Structure

![Untitled](RangeRCNN(2020)%20f45529f71e084593aab079e695adc7d2/Untitled.png)

모델의 전체 구조는 위와 같다. 모델의 input으로 pseudocolor로 변환된 range image를 사용한다.  Range image backbone layer(auto encoder)를 통과하며 range input image는 64 channel feature로 추출되고, 해당 값들은 RV-PV-BEV module을 거치며 BEV 이미지와 pointwise feature로 변환된다. 변환된 값들 중 BEV 이미지를 기반으로 RPN을 거쳐 anchor generation이 이뤄지며 최종적으로 RCNN layer를 거처 bbox 출력이 생성된다.

![Untitled](RangeRCNN(2020)%20f45529f71e084593aab079e695adc7d2/Untitled%201.png)

RCNN layer의 구조이다. 3D proposal의 출력값과 auto encoded range image로부터의 pointwise feature를 flatten하여 입력값으로 사용한다. 해당 값들을 기반으로 box refinement 과정에서 height예측을 포함한다. 

## Loss Function

![Untitled](RangeRCNN(2020)%20f45529f71e084593aab079e695adc7d2/Untitled%202.png)

![Untitled](RangeRCNN(2020)%20f45529f71e084593aab079e695adc7d2/Untitled%203.png)

![Untitled](RangeRCNN(2020)%20f45529f71e084593aab079e695adc7d2/Untitled%204.png)

$L_{rpn}$ : Region proposal network loss

$L_{cls}$ : Focal loss for anchor classification

$L_{reg}$ (rpn): Smooth L1 loss for anchor regression

$L_{dir}$ : Direction classification loss

$L_{rcnn}$ : Region convolutional neural network loss

$L_{score}$ : Confidence prediction loss guided by IoU

$L_{reg}$ (rcnn): Smooth L1 loss for refining proposals 

$L_{corner}$ :  Corner loss

$L_{total}$ : Total loss

$\alpha$ : Regression loss coefficient(in this paper, 2.0)

$\beta$: Direction loss coefficient(in this paper, 0.2)

## Model Performance

### Inference accuracy

- For KITTI validation set

![Untitled](RangeRCNN(2020)%20f45529f71e084593aab079e695adc7d2/Untitled%205.png)

### Inference speed

- For KITTI dataset with a V100 GPU(14.13 TOPS(FP32), Tensor Cores 640, CUDA Cores 5120) : 45ms