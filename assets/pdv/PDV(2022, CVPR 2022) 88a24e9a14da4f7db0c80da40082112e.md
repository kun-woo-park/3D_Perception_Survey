# PDV(2022, CVPR 2022)

[GitHub - TRAILab/PDV: Point Density-Aware Voxels for LiDAR 3D Object Detection (CVPR 2022)](https://github.com/TRAILab/PDV)

## Characteristic(Contributions)

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled.png)

(a) Voxel center based, (b) FPS, (c) Voxel point centroid localization

- 기존의 방법들의 단점을 보완한 voxel point centroid localization제안(Center 기반의 voxel sampling은 낮은 해상도에서 localized된 points 간 misalignment가 발생함, FPS의 경우 sampling한 points들 간의 관계성이 떨어지고, 작은 물체들의 탐지가 어려움)
- Voxel point centroid localization 기반의 density aware roi grid pooling 기법을 제안함(기존의 pcd 처리 기법들은 point들의 density를 feature로써 활용하지 않음(variation이 너무 크기 때문), 이를 KDE([Kernel Density Estimation](https://darkpgmr.tistory.com/147))과 self attention layer로 보완함, 작은 물체(사람, 자전거)탐지에 유리해짐)

## Model Structure

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%201.png)

3D voxel layers로 SECOND에서 사용한 backbone과 유사한 형태를 적용하였다. Voxel backbone의 각 layer에서는 sparse convolution을 사용하여 point cloud data를 인코딩한다. 각 voxel layer는 1x, 2x, 4x, 8x로 down sampling된 해상도를 사용한다. 각 voxel layer의 feature들은 centroid localization을 통해 대표값 centroid로 변환되고, 해당 값들은 density aware grid pooling의 KDE와 self attention layer를 거쳐 인코딩된다. 

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%202.png)

Density aware ROI grid pooling의 ball query(Pyramid RCNN에 나온 개념)에는 (a) 중심부로부터의 상대거리에 따른 offset, (b) 각 point들로부터 KDE를 통해 계산된 probability density 두가지 형태의 feature가 추가되어 point density feature를 적용하였다.

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%203.png)

각 features간의 long range dependency를 고려하기 위해 grid point features에 self attention을 적용하였다. Point density positional encoding에는 grid point로부터의 상대거리 offset과 points의 개수를 사용하여 적용하였다.

## Loss Function

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%204.png)

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%205.png)

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%206.png)

$L_{cls}$ : Focal loss

$L_{reg}$ : Smooth-L1 loss

${y_b}$ : Predicted class vector

${y_b^*}$ : Ground truth class

${r_b}$ : Predicted RoI anchor residual

${r_b^*}$ : Ground truth anchor residual

${\beta}$ : Scaling factor

${p_b}$ : Confidance training target scaled by the 3D RoI

${p_b^*}$ : Ground truth of confidance training target scaled by the 3D RoI (Pyramid RCNN에서 고안된 내용)

${r_b^-}$ : Predicted bounding box residual

${r_b^{-*}}$ : Ground truth bounding box residual

## Model Performance

### Inference accuracy

- For Waymo validation set

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%207.png)

- For KITTI validation set

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%208.png)

### Inference speed

- Titan Xp GPU(12.15 TOPS(FP32), Tensor Cores None, CUDA Cores 3840)

![Untitled](PDV(2022,%20CVPR%202022)%2088a24e9a14da4f7db0c80da40082112e/Untitled%209.png)